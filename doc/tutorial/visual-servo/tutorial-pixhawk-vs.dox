/**

\page tutorial-pixhawk-vs Tutorial: Image-based visual-servoing on a drone equipped with a Pixhawk
\tableofcontents

\section pixhawk_intro Introduction

In this tutorial we show how to control indoor a DJI F450 drone equipped with a Pixhawk that communicates with an embedded
Jetson TX2. Communication between Jetson and Pixhawk is achieved thanks to MAVLink.

[MAVLink](https://mavlink.io/en/) or Micro Air Vehicle Link is a protocol for communicating with small
[unmanned vehicle](https://en.wikipedia.org/wiki/Uncrewed_vehicle). It is designed as a header-only message marshaling library.
In ViSP we don't use directly MAVLink library, but [MavSDK](https://mavsdk.mavlink.io/main/en/index.html) 3rd-party library
that is an interface to MAVLink. The use of MavSDK is possible in ViSP through the use of the vpRobotMavsdk class.

The Jetson retrieves by wifi the position of the drone from a motion capture system that could be in this tutorial provided
by Qualisys or Vicon motion capture systems, thanks to vpMocapQualisys or vpMocapVicon.

To perform visual-servoing, an Intel Realsense D405 camera is also mounted on board and connected to the Jetson. Images are
acquired thanks to vpRealSense2 class. The visual-servoing control law is implemented on the Jetson using vpServo class
and velocities are send to the Pixhawk through MAVLink protocol.

\image html img-drone-dji-pixhawk.jpg DJI F450 equipped with a Pixhawk connected to a Jetson TX2 through an USB link

\section pixhawk_prereq Prerequisites

\subsection pixhawk_prereq_hardware Hardware

The following material is necessary for \ref pixhawk_part1
- A robot equipped with a Pixhawk used to control its motors. In our case we use a DJI F450 drone
- A [Pixhawk](https://pixhawk.org/) mounted on the robot. In our case we use a
  [Pixhawk 2 Cube](https://docs.px4.io/v1.9.0/en/flight_controller/pixhawk-2.html) with
  [PX4 autopilot](https://docs.px4.io/main/)
- A motion capture system (MoCap) like the Qualisys or Vicon ones, that are interfaced through
  vpMocapQualisys and vpMocapVicon respectively.

If you wish to continue this tutorial with \ref pixhawk_part2, the following mat√©rial is also necessary:
- An Intel Realsense camera. In our case we used a D405 camera
- An apriltag that serves as a target to position the drone by visual servoing. See how to \ref apriltag_detection_print.

Since in our use case we want to navigate indoor, GPS is supposed to be not available. That's why
the MoCap is here used to retrieve the robot position using an external computer. This computer could be
a laptop used as a ground station or embedded onboard using for example a Jetson TX2 or a Raspberry Pi4.

The external computer (in our case the Jetson) is used here to stream the pose of the robot from MoCap to the Pixhawk
by using Mavlink.

\subsection pixhawk_prereq_software Software

- <b>MavSDK</b> 3rd party library

  To be able to use MAVLink to communicate between the external computer and the onboard Pixhawk
you need to install MavSDK. Instructions to install MavSDK and check the installation are provided
[here](https://mavsdk.mavlink.io/v0.35.0/en/getting_started/installation.html). Notice that you can get
the latest binary packages (.deb, .rpm) on their [github page](https://github.com/mavlink/MAVSDK/releases).
Once MavSDK is installed (either from binary packages or from source) and enabled during ViSP cmake configuration stage,
it will enable vpRobotMavlink usage.

- <b>QGroundControl</b> software, Ground Control Station for the MAVLink protocol

  When using PX4, it is important to install [QGroundControl](http://qgroundcontrol.com/) (QGC) following instructions
[here](https://docs.qgroundcontrol.com/master/en/getting_started/download_and_install.html).
This software will provide a complete interface with your PX4 flight controller. In the setup window, accessible
directly from the QGC icon, you can flash the firmware on the Pixhawk once it is connected through USB.
We recommend flashing the latest stable version of PX4, but it is possible to go for the developper version.

  Once the PX4 firmware is installed, the various sensor calibrations must be done.
After this, the drone must be configured to fly indoors. In Vehicle Setup, go to Parameters and search the parameter
EKF2_AID_MASK. This parameter allows you to control the source of the position data used in the Kalman filter. If we
want to fly inside, we need to untick the "use GPS" box (default param) and tick the "vision position fusion" and
"vision yaw fusion" boxes. The parameter EKF2_HGT_MODE determines which sensor should be prioritized for altitude
estimation. This parameter should be switched from "barometer" to "Vision".

- <b>MavProxy</b> software

  [MavProxy](https://ardupilot.org/mavproxy/) is another useful software, allowing you to easily communicate with the
drone by merging MAVLink instructions coming through different ports. The instruction to install MavProxy on the
ground station or on the onboard computer (Jetson) can be found
[here](https://ardupilot.org/mavproxy/docs/getting_started/download_and_installation.html).
Once MavProxy is installed on the onboard computer, you can launch it through the terminal from your ground station with ssh.
Then you can run MavProxy with different ports open, as it is shown in this example (by default, QGroundControl will
connect through the udp port 14552) entering your MavProxy directory, generally `$HOME/.local/bin`:
\verbatim
$ cd $MAVPROXY_DIR
$ mavproxy.py --master=/dev/ttyACM0 --out=udpout:192.168.30.111:14550 \
    --out=udpout:192.168.30.111:14551 --out=udpout:192.168.30.111:14552
\endverbatim

\section pixhawk_part1 Part 1: Control the drone indoor
\subsection pixhawk_stream_mocap Stream MoCap to Pixhawk

The code sendMocapToPixhawk.cpp allows you to send the mocap stream comming from a Qualisys or Vicon motion capture system
to your drone. This code is based on MavSDK and Visp's vpMocap classes.
In our case we are connecting a laptop running Ubuntu 22.04 to the Pixhawk via a Jetson on Ubuntu 22.04 running Mavproxy.

The code can be launched for Qualisys in this way :
\verbatim
$ cd $VISP_WS/visp-build/example/servo-pixhawk
$ ./sendMocapToPixhawk -ob DJI-F450 --mocap-system q -d udp://:14551
\endverbatim

If you want to launch the code with Vicon, you can do it this way :
\verbatim
$ ./sendMocapToPixhawk -ob DJI-F450 --mocap-system v -d udp://:14551
\endverbatim

The parameter '-ob' or '--only-body' tells the application which body is to be selected amongst the packets sent by your
Mocap System.
If you look at the window of the mocap system manager, you should be able to look at the bodies' names.

\image html img-dji-qualisys.png Capture of Qualisys Task Manager showing the body 'DJI-F450' corresponding to the drone. width=90%


\subsection pixhawk_test Testing the drone

Before launching the keyboard control test or the visual servoing test, we advise you to launch simpler and safer tests beforehand.
These tests are, in order :
 - testPixhawkDroneTakeoff.cpp : a simple takeoff followed by a landing.
 - testPixhawkDronePositionControl.cpp : a takeoff followed by a square trajectory with a control on the drone's position.
 - testPixhawkDroneVelocityControl.cpp : a takeoff followed by a simple trajectory testing a few different movements using velocity control.

You can easily launch these tests (here is the example for the Takeoff) by connecting through ssh to your Jetson :

\verbatim
terminal 1 $ cd $MAVPROXY_DIR
terminal 1 $ mavproxy.py --master=/dev/ttyACM0 --out=udpout:<IP>:14550 \
    --out=udpout:<IP>:14551 --out=udpout:<IP>:14552
terminal 2 $ ./testPixhawkDroneTakeoff udp://<IP>:14552
\endverbatim


\subsection pixhawk_fly Control the drone with a keyboard

In testPixhawkDroneKeyboard.cpp you will find the code of an example that allows to control the drone from a ground station.
In our case we are connecting a laptop running Ubuntu 22.04 to the Pixhawk using MavProxy.

To use this example:

\verbatim
terminal 1 $ cd $MAVPROXY_DIR
terminal 1 $ mavproxy.py --master=/dev/ttyACM0 --out=udpout:<IP>:14550 \
    --out=udpout:<IP>:14551 --out=udpout:<IP>:14552
terminal 2 $ ./testPixhawkDroneKeyboard --co udp://<IP>:14552
\endverbatim

\section pixhawk_part2 Part 2: Visual Servoing
\subsection pixhawk_servo Image-based visual servoing

In order to do this part, make sure you add a camera to your drone. We added a intel Realsense D405 connected to the
Jetson through USB.

The code servoPixhawkDroneIBVS.cpp is an example that allows to do visual servoing with the drone.
This program estabishes a rigid link between the drone (equiped with a camera) and an Apriltag.
Depending on where the camera is placed, the matrices expressing the transformation between the frame of the drone and the
frame of the camera. Here is a picture of the drone showing where the D405 camera was placed.

\image html img-dji-frames.jpg Frames of the end effector drone frame (e) and of the D405 camera frame (c). width=70%

If you want to launch the code, you can connect to your Jetson through ssh and do :
\verbatim
$ ./servoPixhawkDroneIBVS --tag-size <tag size in meters> --co udp://<IP>:<Port> --distance-to-tag <desired dist to tag in meters>
\endverbatim

\section pixhawk_next Next tutorial

The next tutorial \ref tutorial-bebop2-vs shows how to embbed a visual-servoing scheme on a Parrot Bebop2 drone.

*/
